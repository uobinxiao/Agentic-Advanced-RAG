{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset from NarrativeQA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use Narrative from Question Generation and RAG Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from Utils import *\n",
    "data_loader = DatasetLoader()\n",
    "from datasets import load_dataset\n",
    "import os\n",
    "\n",
    "vector_DB = VectorDatabase()\n",
    "embedder = Embedder()\n",
    "data_processor = DataProcessor(embedder=embedder, vectordatabase=vector_DB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_DB.list_collections()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_narrativeqa_text(split='train'):\n",
    "    # 載入數據集\n",
    "    dataset = load_dataset(\"deepmind/narrativeqa\", split=split)\n",
    "    \n",
    "    # 用於存儲唯一文本的字典\n",
    "    unique_summaries = {}\n",
    "    unique_documents = {}\n",
    "    \n",
    "    total_summary_chars = 0\n",
    "    total_document_chars = 0\n",
    "    \n",
    "    # 用於存儲問題和答案的列表\n",
    "    questions = []\n",
    "    answers = []\n",
    "    \n",
    "    # 從每個示例中提取文本\n",
    "    for example in dataset:\n",
    "        summary = example['document']['summary']['text']\n",
    "        document = example['document']['text']\n",
    "        metadata = example['document']['kind'] + \"\\\\\" + example['document']['summary']['title']\n",
    "        \n",
    "        # 只有當摘要和文檔都是唯一的時才添加到 df_doc\n",
    "        if summary not in unique_summaries and document not in unique_documents:\n",
    "            unique_summaries[summary] = metadata\n",
    "            unique_documents[document] = metadata\n",
    "            total_summary_chars += len(summary)\n",
    "            total_document_chars += len(document)\n",
    "        \n",
    "        # 總是添加問題和答案到 df_qa\n",
    "        questions.append(example['question']['text'])\n",
    "        answers_text = \"\"\n",
    "        for answer in example['answers']:\n",
    "            answers_text += answer['text'] + \", \"\n",
    "        answers.append(answers_text)\n",
    "            \n",
    "    # 從字典創建列表\n",
    "    summaries = list(unique_summaries.keys())\n",
    "    documents = list(unique_documents.keys())\n",
    "    metadata = [unique_summaries[s] for s in summaries]  # 將元數據與摘要對齊\n",
    "    \n",
    "    # 計算平均值\n",
    "    num_examples = len(summaries)\n",
    "    avg_summary_chars = total_summary_chars / num_examples if num_examples > 0 else 0\n",
    "    avg_document_chars = total_document_chars / num_examples if num_examples > 0 else 0\n",
    "    \n",
    "    # 創建 df_doc DataFrame\n",
    "    df_doc = pd.DataFrame({\n",
    "        'summary': summaries,\n",
    "        'document': documents,\n",
    "        'metadata': metadata\n",
    "    })\n",
    "    \n",
    "    # 創建 df_qa DataFrame\n",
    "    df_qa = pd.DataFrame({\n",
    "        'questions': questions,\n",
    "        'ground_truths': answers,\n",
    "        'answers': ['' for _ in range(len(questions))],\n",
    "        'context': ['' for _ in range(len(questions))]\n",
    "    })\n",
    "    \n",
    "    print(f'唯一文檔數量: {num_examples}')\n",
    "    print(f'問答對數量: {len(df_qa)}')\n",
    "    print(f'平均摘要長度: {avg_summary_chars:.2f} 字符')\n",
    "    print(f'平均文檔長度: {avg_document_chars:.2f} 字符')\n",
    "    \n",
    "    return df_doc, df_qa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_doc, df_qa = extract_narrativeqa_text(split=\"train\")\n",
    "# df_doc.to_parquet(\".parquet/narrative_qa_doc_full.parquet\")\n",
    "# df_qa.to_parquet(\".parquet/narrative_qa_qa_full.parquet\")\n",
    "df_doc = pd.read_parquet(\".parquet/narrative_qa_doc_full.parquet\")\n",
    "df_qa = pd.read_parquet(\".parquet/narrative_qa_qa_full.parquet\")\n",
    "\n",
    "df_doc_sample = df_doc.sample(frac=0.01, random_state=42)\n",
    "# df_qa_sample = df_qa.sample(frac=0.05, random_state=42)\n",
    "df_doc_sample.to_parquet(\".parquet/narrative_qa_doc_sample_11.parquet\")\n",
    "# df_qa_sample.to_parquet(\".parquet/narrative_qa_qa_sample_11.parquet\")\n",
    "# df_doc_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load parquet\n",
    "df_doc_sample = pd.read_parquet(\".parquet/narrative_qa_doc_sample_11.parquet\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform the dataframe into .txts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import unicodedata\n",
    "\n",
    "def preprocess_content(content: str) -> str:\n",
    "    soup = BeautifulSoup(content, 'html.parser')\n",
    "    text = soup.get_text()\n",
    "\n",
    "    # unify to NFKC normalization form\n",
    "    text = unicodedata.normalize('NFKC', text)\n",
    "\n",
    "    # remove url\n",
    "    text = re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', '', text)\n",
    "\n",
    "    # remove extra whitespace\n",
    "    text = re.sub(r'[ \\t]+', ' ', text).strip()\n",
    "\n",
    "    # remove special characters, but keep some punctuation\n",
    "    text = re.sub(r'[^\\w\\s.,!?;:()\"-]', '', text)\n",
    "\n",
    "    # unify quotes\n",
    "    text = text.replace('\"', '\"').replace('\"', '\"')\n",
    "\n",
    "    # remove consecutive punctuation\n",
    "    text = re.sub(r'([.,!?;:])\\1+', r'\\1', text)\n",
    "\n",
    "    # ensure there is appropriate whitespace between sentences\n",
    "    text = re.sub(r'([.,!?;:])\\s*', r'\\1 ', text)\n",
    "\n",
    "    return text.strip()\n",
    "\n",
    "def write_text_to_files_by_metadata(df):\n",
    "    # Ensure the dataframe has the required columns\n",
    "    if not all(col in df.columns for col in ['document', 'metadata']):\n",
    "        raise ValueError(\"Dataframe must contain 'document' and 'metadata' columns\")\n",
    "\n",
    "    os.makedirs(\".txt/\", exist_ok=True)\n",
    "    \n",
    "    # Dictionary to keep track of file handles\n",
    "    file_handles = {}\n",
    "\n",
    "    try:\n",
    "        for _, row in df.iterrows():\n",
    "            metadata = row['metadata']\n",
    "            metadata = metadata.replace(\" \", \"_\").replace(\"/\", \"_\").replace(\"\\\\\", \"_\").replace(\":\", \"_\").replace(\"\\\"\", \"\")\n",
    "            document = preprocess_content(row['document'])\n",
    "\n",
    "            # Create or get file handle\n",
    "            if metadata not in file_handles:\n",
    "                filename = f\".txt/{metadata}.txt\"\n",
    "                file_handles[metadata] = open(filename, 'a', encoding='utf-8')\n",
    "\n",
    "            # Write document to file\n",
    "            file_handles[metadata].write(document + \"\\n\\n\")  # Add two newlines for separation\n",
    "\n",
    "    finally:\n",
    "        # Close all file handles\n",
    "        for handle in file_handles.values():\n",
    "            handle.close()\n",
    "\n",
    "    print(f\"Files created: {', '.join(f'{metadata}.txt' for metadata in file_handles.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_text_to_files_by_metadata(df_doc_sample)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedder into Milvus (GPU) for txts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_processor.directory_files_process(\"narrative_qa_full_gpu\", \".txt/\", True, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import GRAPH RAG data to neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knowledge_DB = KnowledgeGraphDatabase()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knowledge_DB.transform_graph_rag_to_neo4j(datapath=\"../graph_rag_sample/output/20240906-153334/artifacts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = Retriever()\n",
    "retriever.global_retrieve(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Modular RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "rag_evaluation_dataset = pd.read_parquet(\".parquet/narrative_qa_qa_sample_11.parquet\")\n",
    "dataset_queries = rag_evaluation_dataset[\"questions\"].tolist()[5:10:]\n",
    "print(dataset_queries)\n",
    "# print(vector_DB.list_collections())\n",
    "answer = rag_evaluation_dataset[\"ground_truths\"].tolist()[5:10:]\n",
    "print(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Module import *\n",
    "from Config.output_pydantic import *\n",
    "from langchain_core.runnables.config import RunnableConfig\n",
    "from IPython.display import Image\n",
    "\n",
    "\n",
    "config = RunnableConfig(recursion_limit=1000000)\n",
    "workflow = WorkFlowModularHybridRAG()\n",
    "\n",
    "results = workflow.graph.stream({\n",
    "    \"dataset_queries\": dataset_queries,\n",
    "    \"specific_collection\": \"narrative_qa_full_gpu\",\n",
    "}, config=config)\n",
    "\n",
    "for result in results:\n",
    "    print(result)\n",
    "\n",
    "\n",
    "Image(workflow.graph.get_graph().draw_mermaid_png())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[\"all_results\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Module import *\n",
    "from Config.output_pydantic import *\n",
    "workflow = WorkFlowModularHybridRAG_Unit_Function_Test()\n",
    "\n",
    "results = workflow.graph.stream({\n",
    "    \"specific_collection\": \"narrative_qa_full_gpu\",\n",
    "    \"user_query\": \"What is the main topic of this dataset?\",\n",
    "})\n",
    "\n",
    "\n",
    "from IPython.display import Image\n",
    "\n",
    "# Image(workflow.graph.get_graph().draw_mermaid_png())\n",
    "for result in results:\n",
    "    print(result)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from typing import Annotated, TypedDict\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.constants import Send\n",
    "from langgraph.graph import END, StateGraph, START\n",
    "\n",
    "# NOTE:\n",
    "# - if you're using langchain-core >= 0.3, you need to use pydantic v2\n",
    "# - if you're using langchain-core >= 0.2,<0.3, you need to use pydantic v1\n",
    "from langchain_core import __version__ as core_version\n",
    "from packaging import version\n",
    "\n",
    "core_version = version.parse(core_version)\n",
    "if (core_version.major, core_version.minor) < (0, 3):\n",
    "    from pydantic.v1 import BaseModel, Field\n",
    "else:\n",
    "    from pydantic import BaseModel, Field\n",
    "\n",
    "# Model and prompts\n",
    "# Define model and prompts we will use\n",
    "subjects_prompt = \"\"\"Generate a comma separated list of between 2 and 5 examples related to: {topic}.\"\"\"\n",
    "joke_prompt = \"\"\"Generate a joke about {subject}\"\"\"\n",
    "best_joke_prompt = \"\"\"Below are a bunch of jokes about {topic}. Select the best one! Return the ID of the best one.\n",
    "\n",
    "{jokes}\"\"\"\n",
    "\n",
    "\n",
    "class Subjects(BaseModel):\n",
    "    subjects: list[str]\n",
    "\n",
    "\n",
    "class Joke(BaseModel):\n",
    "    joke: str\n",
    "\n",
    "\n",
    "class BestJoke(BaseModel):\n",
    "    id: int = Field(description=\"Index of the best joke, starting with 0\", ge=0)\n",
    "\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "# Graph components: define the components that will make up the graph\n",
    "\n",
    "\n",
    "# This will be the overall state of the main graph.\n",
    "# It will contain a topic (which we expect the user to provide)\n",
    "# and then will generate a list of subjects, and then a joke for\n",
    "# each subject\n",
    "class OverallState(TypedDict):\n",
    "    topic: str\n",
    "    subjects: list\n",
    "    # Notice here we use the operator.add\n",
    "    # This is because we want combine all the jokes we generate\n",
    "    # from individual nodes back into one list - this is essentially\n",
    "    # the \"reduce\" part\n",
    "    jokes: Annotated[list, operator.add]\n",
    "    best_selected_joke: str\n",
    "\n",
    "\n",
    "# This will be the state of the node that we will \"map\" all\n",
    "# subjects to in order to generate a joke\n",
    "class JokeState(TypedDict):\n",
    "    subject: str\n",
    "\n",
    "\n",
    "# This is the function we will use to generate the subjects of the jokes\n",
    "def generate_topics(state: OverallState):\n",
    "    prompt = subjects_prompt.format(topic=state[\"topic\"])\n",
    "    response = model.with_structured_output(Subjects).invoke(prompt)\n",
    "    return {\"subjects\": response.subjects}\n",
    "\n",
    "\n",
    "# Here we generate a joke, given a subject\n",
    "def generate_joke(state: JokeState):\n",
    "    prompt = joke_prompt.format(subject=state[\"subject\"])\n",
    "    response = model.with_structured_output(Joke).invoke(prompt)\n",
    "    return {\"jokes\": [response.joke]}\n",
    "\n",
    "\n",
    "# Here we define the logic to map out over the generated subjects\n",
    "# We will use this an edge in the graph\n",
    "def continue_to_jokes(state: OverallState):\n",
    "    # We will return a list of `Send` objects\n",
    "    # Each `Send` object consists of the name of a node in the graph\n",
    "    # as well as the state to send to that node\n",
    "    return [Send(\"generate_joke\", {\"subject\": s}) for s in state[\"subjects\"]]\n",
    "\n",
    "\n",
    "# Here we will judge the best joke\n",
    "def best_joke(state: OverallState):\n",
    "    jokes = \"\\n\\n\".join(state[\"jokes\"])\n",
    "    prompt = best_joke_prompt.format(topic=state[\"topic\"], jokes=jokes)\n",
    "    response = model.with_structured_output(BestJoke).invoke(prompt)\n",
    "    return {\"best_selected_joke\": state[\"jokes\"][response.id]}\n",
    "\n",
    "\n",
    "# Construct the graph: here we put everything together to construct our graph\n",
    "graph = StateGraph(OverallState)\n",
    "graph.add_node(\"generate_topics\", generate_topics)\n",
    "graph.add_node(\"generate_joke\", generate_joke)\n",
    "graph.add_node(\"best_joke\", best_joke)\n",
    "graph.add_edge(START, \"generate_topics\")\n",
    "graph.add_conditional_edges(\"generate_topics\", continue_to_jokes, [\"generate_joke\"])\n",
    "graph.add_edge(\"generate_joke\", \"best_joke\")\n",
    "graph.add_edge(\"best_joke\", END)\n",
    "app = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in app.stream({\"topic\": \"animals\"}):\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test out Retriever for local retriever and global retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Utils import *\n",
    "retriever = Retriever()\n",
    "knowledge_DB = KnowledgeGraphDatabase()\n",
    "# knowledge_DB.create_entity_vector_index()\n",
    "# knowledge_DB.create_community_weight()\n",
    "global_result = retriever.global_retrieve(0)\n",
    "local_result = retriever.local_retrieve([\"What is the meaning of life\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_result[\"communities\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Config.constants as const\n",
    "import json\n",
    "from MultiAgent import *\n",
    "from Utils import *\n",
    "\n",
    "retriever = Retriever()\n",
    "multi_agent = MultiAgent_RAG()\n",
    "# all_communities = retriever.global_retrieve(0)[\"communities\"]\n",
    "\n",
    "# batches = []\n",
    "# for i in range(0, len(all_communities), const.NODE_BATCH_SIZE):\n",
    "#     batch_communities = all_communities[i:i + const.NODE_BATCH_SIZE]\n",
    "#     batches.append({\n",
    "#         \"user_query\": \"What is the meaning of life\",\n",
    "#         \"sub_queries\": [],\n",
    "#         \"batch_communities\": batch_communities,\n",
    "#         \"batch_size\": len(batch_communities),\n",
    "#     })\n",
    "\n",
    "\n",
    "# all_scores = multi_agent.topic_reranking_run_batch_async(node_batch_inputs=batches).relevant_scores\n",
    "# print(all_scores)\n",
    "# print(len(all_scores))\n",
    "# print(len(all_communities))\n",
    "\n",
    "multi_agent.user_query_classification_run(user_query=\"Why does the author choose to use first-person point of view in this article?\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Utils import *\n",
    "retriever = Retriever()\n",
    "retriever.hybrid_retrieve(collection_name=\"narrative_qa_full_gpu\", query_texts=[\"What is the meaning of life\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "poetry310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
